# -*- coding: utf-8 -*-
"""Query Patterns & Data Access Design.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ES6gAb3CbLCkczyYAm4BD3n-WrODgU3C
"""

'''
Read vs Write Patterns
Analyze the following systems and identify which are read-heavy or write-heavy:

Logging systems
Reporting dashboards
Transactional APIs

ANS - Understanding whether a system is read-heavy or write-heavy is one of the most important decisions in data engineering. It dictates which database you choose, how you index your data, and how you handle hardware costs.

1. Logging Systems (e.g., Airflow Logs, CloudWatch)
Primary Operation: INSERT (Append-only)

Classification: Write-Heavy

Why: For every single action in a system (a user clicking a button, a DAG task starting, an error occurring), a new line of text is generated. These events happen constantly and simultaneously. However, people only read logs when something goes wrong or during an audit—which is rare compared to the constant stream of incoming data.

Implications for Storage Design:

LSM Trees: Storage engines like those in Cassandra or RocksDB are preferred because they optimize for sequential writes.

No Indexes: You minimize indexes because every index slows down the write speed.

Compression: Since logs are mostly repetitive text, heavy compression is used to save disk space.

2. Reporting Dashboards (e.g., Tableau, PowerBI)
Primary Operation: SELECT (Aggregations like SUM, AVG)

Classification: Read-Heavy

Why: Data is usually loaded into a reporting tool once (often via an Airflow DAG at night), but it is queried hundreds of times throughout the day by managers and analysts. One "Write" (the data load) supports thousands of "Reads" (filtering, slicing, and viewing the dashboard).

Implications for Storage Design:

Columnar Storage: Databases like BigQuery or Snowflake store data in columns rather than rows, making it lightning-fast to sum up a single column (like "Total Sales") across billions of rows.

Heavy Indexing/Caching: You use materialized views and result-caching to ensure that when a user refreshes their dashboard, the answer is ready instantly.

3. Transactional APIs (e.g., Uber Ride Request, Bank Transfer)
Primary Operation: Balanced READ and WRITE (usually categorized as High-Concurrency)

Classification: Write-Intensive with Strict Read Requirements

Why: Think of an Uber request. You read the available drivers (Read), you write the request to the database (Write), the driver updates their status (Write), and you read their location (Read). It’s a constant back-and-forth where every write must be immediately readable by the next party.

Implications for Storage Design:

ACID Compliance: You need an RDBMS that handles "Locking" well so two people don't book the same ride.

Low Latency: The database must be optimized for "Point Lookups" (finding exactly one ID quickly) rather than scanning the whole table.

IOPS: You need fast SSDs (High Input/Output Operations Per Second) to handle the constant chatter.
'''

'''
Aggregation vs Embedding
Explain:

When aggregation queries dominate
When document embedding is preferable
Impact on performance and maintenance

ANS - In data architecture, the choice between Aggregation and Embedding is essentially a choice between "calculating on the fly" versus "storing data exactly how you'll use it."

1. When Aggregation Queries Dominate
What are they?
Aggregation queries involve taking many individual rows and "summarizing" them into a single result using functions like SUM(), AVG(), COUNT(), or GROUP BY.

When do they dominate?
They dominate in Analytical (OLAP) environments where the goal is to find trends rather than individual records. If your users are constantly asking "What were the total sales in Q3?" or "What is the average age of our users?", you are in an aggregation-heavy environment.

Storage Systems:

Columnar Databases: (Snowflake, BigQuery, Amazon Redshift) are built for this. Because data is stored in columns, the engine only reads the "Price" column to calculate a sum, skipping all other data.

In-Memory Engines: (Redis, Apache Spark) for real-time aggregations.

2. When Document Embedding is Preferable
What is it?
Embedding is a NoSQL concept (primarily in Document Stores) where you store "child" data directly inside the "parent" record. Instead of having a separate table for "Comments," you store an array of comments inside the "Post" document.

When is it preferable?
It is preferable when data is always read together. If you almost never look at a "Comment" without looking at the "Post" it belongs to, embedding saves you from doing a "Join." It is also best for One-to-Few relationships.

Storage Systems:

Document Stores: (MongoDB, CouchDB).

Key-Value Stores: (DynamoDB) using complex JSON values.

3. When to Choose Each Approach
Choose Aggregation (SQL) when:
You need to perform ad-hoc analysis (you don't know what questions you'll ask tomorrow).

Data integrity is the top priority (e.g., Prices, Account Balances).

You have Many-to-Many relationships.

Choose Embedding (NoSQL) when:
You have a high-traffic application where millisecond response time is critical.

The data has a naturally hierarchical structure (e.g., a Blog post with its Tags and Comments).

You want to scale horizontally across many servers easily.

Real-World Example
If you are building a Library System:

Aggregate for the Reports: "How many books were checked out this month?"

Embed for the Book Detail Page: Store the Author's bio and the Book's chapters directly in the Book's JSON document so the app loads instantly.
'''

'''
3. Pattern Mapping (15 mins)
Map query patterns to storage systems:

RDBMS
Document stores
Columnar systems

ANS - To build an efficient data architecture, you must match your Query Pattern (how you ask for data) to the Storage System (how the data is physically laid out on the disk).

Using the wrong system is like trying to find a specific word in a library by reading every book from page one—it works eventually, but it's incredibly inefficient.

1. RDBMS (Relational Databases)
Best for: Complex Relationships and "Point" Lookups.

Query Patterns: * Joins: Connecting multiple entities (e.g., "Show me the customer name, their last order, and the shipping status").

Filtering by Multiple Criteria: Finding specific records using various attributes (WHERE city='London' AND age > 25).

Single-Row Updates: Changing one specific value quickly (e.g., updating a bank balance).

Why: RDBMS uses B-Tree Indexes, which act like a detailed book index. They allow the database to jump directly to a specific row. Because data is "Normalized" (stored in separate tables), it ensures no data is wasted or duplicated.

Examples: PostgreSQL, MySQL, SQL Server.

2. Document Stores (NoSQL)
Best for: Hierarchical Data and "Object-Based" Retrieval.

Query Patterns:

Full-Document Fetch: Grabbing a large, complex object in one go (e.g., "Load the entire user profile including their settings, preferences, and recent activity").

Flexible Schema Queries: Searching for data where the fields might vary (e.g., searching a product catalog where some items have 'Voltage' and others have 'Fabric').

Why: Data is stored as JSON-like documents. Since all related data is "embedded" inside the document, there are no joins. The database reads one contiguous block from the disk, which is significantly faster for application rendering.

Examples: MongoDB, CouchDB.

3. Columnar Systems
Best for: Massive Aggregations and Analytical Scanning.

Query Patterns:

Column-Wide Aggregation: Calculating statistics across millions of rows (e.g., "What was the total revenue for the last 5 years?").

Filtering by Values: Scanning a single attribute across the entire dataset (e.g., "Count all users where 'status' = 'active'").

Why: Traditional databases store data in Rows (everything about User 1, then everything about User 2). Columnar systems store all Names together, then all Prices together. If you only need the "Price," the system skips 90% of the data on the disk, making analytical queries 100x–1000x faster.

Examples: Snowflake, Google BigQuery, Amazon Redshift.

'''

'''
4. Design Reflection (10 mins)
Summarize how query patterns influence:

Schema design
Storage choice
Indexing strategy

ANS - Design reflection in data engineering is the practice of "working backward." You don't build a database based on what the data is; you build it based on how the data will be queried.

1. Schema Design
The way you structure your tables or documents is a direct response to your operational needs.

Read Patterns: If you need to read data fast (e.g., a website profile), you De-normalize. You combine related data into one table or document to avoid expensive joins.

Example: Storing a user's "Last 5 Orders" directly inside their User record.

Write Patterns: If you are writing data constantly (e.g., a stock ticker), you Normalize. You keep tables slim and simple to ensure the database can "keep up" with the incoming stream without locking up.

Example: Separating Transactions from User_Profiles to keep the transaction table as small as possible.

Aggregation Needs: If you need to sum up millions of rows, you use Columnar Schemas. You group similar data types together to allow the hardware to skip irrelevant data.

Example: Using a "Star Schema" where a central Sales table is surrounded by small descriptor tables.

. Storage Choice
Query patterns are the primary driver for selecting your "engine."

Factors that matter most:

Latency: Does the user need the answer in 10ms (RDBMS/NoSQL) or 10 seconds (Warehouse)?

Volume: Are we talking about 10,000 rows or 10 billion?

Structure: Is the data predictable (SQL) or messy/changing (NoSQL)?

Examples:Pattern: "Give me a list of all followers for User X." $\rightarrow$ Storage: Graph Database (Neo4j).

Pattern: "Calculate the total tax paid by all users in 2025." $\rightarrow$ Storage: Columnar Warehouse (Snowflake)

3. Indexing Strategy
Indexes are the "fast-pass" lanes of a database. However, they aren't free; they consume space and slow down writes.

Read-Heavy Workloads: You use Heavy Indexing. You might have 5 or 6 indexes on a single table (by Date, by Email, by Status) so that any query finds its target instantly.

Example: A B-Tree Index on a username column for a login system.

Write-Heavy Workloads: You use Minimal Indexing. Every time you write a row, the database also has to update the index. If you have too many indexes, the system will crawl to a halt.

Example: A LSM-Tree (Log-Structured Merge-tree) which is optimized for high-speed sequential writes, often used in logging systems.
'''